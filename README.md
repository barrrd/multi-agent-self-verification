# ğŸ¤– Multi-Agent Scheme with Self-Verification for Multi-Hop Q&A

A multi-agent system designed to mitigate hallucination and enhance information accuracy in complex Multi-Hop Question Answering (QA) tasks, leveraging LangGraph and the OpenAI API with a dynamic correction feedback loop.

## ğŸ“Œ Abstract (Thesis Overview)
Large Language Models (LLMs) often struggle with information retrieval failures and hallucinations in multi-hop QA that requires complex reasoning across multiple documents. While the ReAct framework addresses some of these issues, its linear execution structure propagates initial retrieval errors to subsequent steps without correction, leading to final answer failures. Furthermore, the lack of a self-verification mechanism degrades system robustness. 

To overcome this, we propose a **multi-agent scheme equipped with a Self-Verification mechanism**. Five specialized agents (Planner, Reasoner, Searcher, Extractor, and Answer) collaborate and evaluate the reliability of collected information during the self-verification phase. Through a **dynamic correction feedback loop (cyclic graph structure)** that either proceeds with reasoning or modifies the search strategy based on verification results, errors are proactively blocked, enhancing the capacity for accurate answer generation. 

Experimental results on the HotpotQA dataset demonstrate that our proposed system achieves an **11.00-point improvement in Exact Match (EM) (a 23.9% increase) and a 15.07-point improvement in F1 score** compared to the baseline ReAct framework. This study proves that structured interaction and verification procedures among specialized agents are essential for improving the accuracy and reliability of multi-hop reasoning.

## ğŸ—ï¸ Architecture & 5 Agents
This system is designed based on LangGraph and consists of five specialized agents (Nodes):

- **ğŸ§  Planner**: Analyzes the user's question and decomposes it into multi-step sub-goals. If a search fails, it dynamically re-plans a new search strategy while preserving meaningful clues found in previous steps.
- **âš™ï¸ Reasoner**: Acts as the control tower of the system. It performs self-verification to determine if the collected evidence is sufficient to achieve the current step's goal. Based on the result, it decides whether to proceed to the next step or request a re-search/re-plan.
- **ğŸ” Searcher**: Identifies and selects the most relevant document for the current reasoning step from the given document pool (Context).
- **ğŸ“„ Extractor**: Precisely extracts only the core evidence (1-2 sentences) relevant to the question from the extensive text of the selected document.
- **ğŸ¯ Answer**: Synthesizes the verified evidence collected across all steps to derive the final answer and its reasoning process.

## ğŸ“‚ Repository Structure
```text
multi-agent-self-verification/
â”œâ”€â”€ src/               
â”‚   â”œâ”€â”€ graph.py       # LangGraph cyclic pipeline build and node connections
â”‚   â”œâ”€â”€ nodes.py       # Core logic for the 5 agents and dynamic correction control
â”‚   â”œâ”€â”€ prompts.py     # System prompts and dynamic variable templates for each agent
â”‚   â”œâ”€â”€ state.py       # System state (QAState) schema definition
â”‚   â””â”€â”€ utils.py       # Helper functions for LLM calls, data loading, and evaluation (EM/F1)
â”œâ”€â”€ scripts/           
â”‚   â””â”€â”€ run_batch.py   # Batch execution and result saving script for the HotpotQA dataset
â”œâ”€â”€ data/              # Dataset directory (HotpotQA json)
â”œâ”€â”€ result/            
â”‚   â””â”€â”€ MultiHop_QA/   # Experimental results storage directory (results.json, summary.json)
â”œâ”€â”€ requirements.txt   # List of dependencies
â””â”€â”€ .env.example       # Environment variables template
